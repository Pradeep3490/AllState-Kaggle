{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#################################################################################################################################\n",
    "#############################AllState Claims Severity Prediction Challenge - Kaggle - October 2016###############################\n",
    "\n",
    "# EDA\n",
    "# Reading in training and test data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%pylab inline\n",
    "df_train = pd.read_csv(\"C:/Users/HP/Desktop/Kaggle/All State Severity Claims/train.csv\")\n",
    "df_test = pd.read_csv(\"C:/Users/HP/Desktop/Kaggle/All State Severity Claims/test.csv\")\n",
    "ID = df_test['id'] # Save ID's of test file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data dimensions:  (188318, 132)\n",
      "Test data dimensions:  (125546, 131)\n"
     ]
    }
   ],
   "source": [
    "# Getting overview of datasets\n",
    "print(\"Train data dimensions: \", df_train.shape)\n",
    "print(\"Test data dimensions: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join both datasets for feature engineering, just in case its needed somewhere. But before introduce a loss column into test and set it to null\n",
    "\n",
    "df_test['loss'] = np.nan\n",
    "df_joined = pd.concat([df_train,df_test])\n",
    "del df_test['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting continuous variables. First we collect our continuous variables names into a list\n",
    "contfeatures = df_train.select_dtypes(include=[\"float64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "contfeatures_colnames = list(contfeatures)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24a2bd67be0>"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCgAAAMBCAYAAAAtbIWMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24a6b2bec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We saw earlier that the data was heavily right skewed for the 'loss' variable. We look at a distribution plot of the variable\n",
    "# after taking its log the data looks normal and ready for any analysis like linear models,etc.\n",
    "\n",
    "plt.figure(figsize=(13,9))\n",
    "sns.distplot(np.log1p(df_train[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>0.83510</td>\n",
       "      <td>0.569745</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.43919</td>\n",
       "      <td>0.338312</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>0.32446</td>\n",
       "      <td>0.381398</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.44467</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10   ...        cont6  \\\n",
       "0    A    B    A    B    A    A    A    A    B     A   ...     0.718367   \n",
       "1    A    B    A    A    A    A    A    A    B     B   ...     0.438917   \n",
       "2    A    B    A    A    B    A    A    A    B     B   ...     0.289648   \n",
       "3    B    B    A    B    A    A    A    A    B     A   ...     0.440945   \n",
       "4    A    B    A    B    A    A    A    A    B     B   ...     0.178193   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646  0.822493   \n",
       "1  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307  0.611431   \n",
       "2  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424  0.195709   \n",
       "3  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570  0.605077   \n",
       "4  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213  0.246011   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.714843  2213.18  \n",
       "1  0.304496  1283.60  \n",
       "2  0.774425  3005.09  \n",
       "3  0.602642   939.85  \n",
       "4  0.432606  2763.85  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can drop the id variable as it does not help in modeling\n",
    "df_train = df_train.iloc[:,1:]\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Checking skewness of continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       -0.002155\n",
      "cont1     0.516424\n",
      "cont2    -0.310941\n",
      "cont3    -0.010002\n",
      "cont4     0.416096\n",
      "cont5     0.681622\n",
      "cont6     0.461214\n",
      "cont7     0.826053\n",
      "cont8     0.676634\n",
      "cont9     1.072429\n",
      "cont10    0.355001\n",
      "cont11    0.280821\n",
      "cont12    0.291992\n",
      "cont13    0.380742\n",
      "cont14    0.248674\n",
      "loss      3.794958\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# variables loss, cont9, cont7 and to an extent cont8 have skew which can be corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = contfeatures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont11 and cont12 = 0.99\n",
      "cont1 and cont9 = 0.93\n",
      "cont6 and cont10 = 0.88\n",
      "cont6 and cont13 = 0.82\n",
      "cont1 and cont10 = 0.81\n",
      "cont6 and cont9 = 0.80\n",
      "cont9 and cont10 = 0.79\n",
      "cont6 and cont12 = 0.79\n",
      "cont6 and cont11 = 0.77\n",
      "cont1 and cont6 = 0.76\n",
      "cont7 and cont11 = 0.75\n",
      "cont7 and cont12 = 0.74\n",
      "cont10 and cont12 = 0.71\n",
      "cont10 and cont13 = 0.71\n",
      "cont10 and cont11 = 0.70\n",
      "cont6 and cont7 = 0.66\n",
      "cont9 and cont13 = 0.64\n",
      "cont9 and cont12 = 0.63\n",
      "cont1 and cont12 = 0.61\n",
      "cont9 and cont11 = 0.61\n",
      "cont1 and cont11 = 0.60\n",
      "cont1 and cont13 = 0.53\n",
      "cont4 and cont8 = 0.53\n"
     ]
    }
   ],
   "source": [
    "# Correlation analysis\n",
    "\n",
    "cols = contfeatures.columns\n",
    "\n",
    "corr = contfeatures.corr()\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "cor_list = []\n",
    "\n",
    "for i in range (0,len(size)):\n",
    "    for j in range(i+1,len(size)):\n",
    "        if (corr.iloc[i,j] >= threshold and corr.iloc[i,j] <1) or (corr.iloc[i,j] < 0 and corr.iloc[i,j] <= -threshold):\n",
    "            cor_list.append([corr.iloc[i,j],i,j])\n",
    "\n",
    "# Sort to show highest corrleated pairs first\n",
    "\n",
    "s_cor_list = sorted(cor_list,key=lambda x: -abs(x[0]))\n",
    "\n",
    "#Print correlations and column names\n",
    "for v,i,j in s_cor_list:\n",
    "    print (\"%s and %s = %.2f\" % (cols[i],cols[j],v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cont11, cont1, cont6, cont9, cont7,cont10 can be removed from training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing these variables from our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_features = ['cont11','cont1','cont6','cont9','cont10']\n",
    "df_train = df_train.drop(df_train[corr_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test.drop(df_test[corr_features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train['logloss'] = np.log1p(df_train['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "      <td>7.702637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "      <td>7.158203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "      <td>8.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "      <td>6.846784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "      <td>7.924742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10    ...        cont3  \\\n",
       "0    A    B    A    B    A    A    A    A    B     A    ...     0.187583   \n",
       "1    A    B    A    A    A    A    A    A    B     B    ...     0.592681   \n",
       "2    A    B    A    A    B    A    A    A    B     B    ...     0.484196   \n",
       "3    B    B    A    B    A    A    A    A    B     A    ...     0.527991   \n",
       "4    A    B    A    B    A    A    A    A    B     B    ...     0.527991   \n",
       "\n",
       "      cont4     cont5     cont7    cont8    cont12    cont13    cont14  \\\n",
       "0  0.789639  0.310061  0.335060  0.30260  0.594646  0.822493  0.714843   \n",
       "1  0.614134  0.885834  0.436585  0.60087  0.366307  0.611431  0.304496   \n",
       "2  0.236924  0.397069  0.315545  0.27320  0.373424  0.195709  0.774425   \n",
       "3  0.373816  0.422268  0.391128  0.31796  0.321570  0.605077  0.602642   \n",
       "4  0.473202  0.704268  0.247408  0.24564  0.202213  0.246011  0.432606   \n",
       "\n",
       "      loss   logloss  \n",
       "0  2213.18  7.702637  \n",
       "1  1283.60  7.158203  \n",
       "2  3005.09  8.008396  \n",
       "3   939.85  6.846784  \n",
       "4  2763.85  7.924742  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catfeatures = df_train.select_dtypes(include=[\"object\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catfeatures_list = list(catfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In training set check for varbs with >10 levels\n",
    "\n",
    "catvarbs_10 = list((df_train[catfeatures_list].apply(pd.Series.nunique)>10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catvarlist = []\n",
    "for (i, v) in zip(catfeatures_list, catvarbs_10):\n",
    "    if(v):\n",
    "        catvarlist.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat99', 'cat100', 'cat101', 'cat103', 'cat104', 'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat110', 'cat111', 'cat112', 'cat113', 'cat114', 'cat115', 'cat116']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(catvarlist)\n",
    "len(catvarlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# There are 17 such categorical variables we must work upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>B</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>BU</td>\n",
       "      <td>BC</td>\n",
       "      <td>C</td>\n",
       "      <td>AS</td>\n",
       "      <td>S</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>LB</td>\n",
       "      <td>7.702637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CQ</td>\n",
       "      <td>A</td>\n",
       "      <td>AV</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DP</td>\n",
       "      <td>7.158203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>O</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>AB</td>\n",
       "      <td>DK</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>AF</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>GK</td>\n",
       "      <td>8.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>AE</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>DJ</td>\n",
       "      <td>6.846784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>K</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>BM</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>CK</td>\n",
       "      <td>7.924742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat99 cat100 cat101 cat103 cat104 cat105 cat106 cat107 cat108 cat109 cat110  \\\n",
       "0     T      B      G      A      I      E      G      J      G     BU     BC   \n",
       "1     T      L      F      A      E      E      I      K      K     BI     CQ   \n",
       "2     D      L      O      B      E      F      H      F      A     AB     DK   \n",
       "3     T      I      D      A      E      E      I      K      K     BI     CS   \n",
       "4     P      F      J      A      D      E      K      G      B      H      C   \n",
       "\n",
       "  cat111 cat112 cat113 cat114 cat115 cat116   logloss  \n",
       "0      C     AS      S      A      O     LB  7.702637  \n",
       "1      A     AV     BM      A      O     DP  7.158203  \n",
       "2      A      C     AF      A      I     GK  8.008396  \n",
       "3      C      N     AE      A      O     DJ  6.846784  \n",
       "4      C      Y     BM      A      K     CK  7.924742  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding all categorical variables with >10 levels using supervised ratio- something similar to Owen Zhang's Leave one out \n",
    "#Encoding technique\n",
    "\n",
    "# Getting all those categorical variables into a new dataset\n",
    "# WE append 'loss' variable to the cat varb dataset to compute means and variance\n",
    "\n",
    "catvarlist.append('logloss')\n",
    "df_cat_encod = df_train[catvarlist]\n",
    "df_cat_encod.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'newcat99'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing mean & variance values of target for each category by each level\n",
    "\n",
    "#before running our function to encode, we need to ensure that the list of char variables which we pass to the function\n",
    "#does not the 'loss' variable in it\n",
    "\n",
    "catvarlist.remove('logloss')\n",
    "catvarlist\n",
    "target=['logloss']\n",
    "\"new\"+catvarlist[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Putting everything into a function\n",
    "\n",
    "#But Before that, we define a function which will flatten a multi index column names which are created after aggregation of data\n",
    "def flattenHierarchicalCol(col,sep = ','):\n",
    "    if not type(col) is tuple:\n",
    "        return col\n",
    "    else:\n",
    "        new_col = ''\n",
    "        for leveli,level in enumerate(col):\n",
    "            if not level == '':\n",
    "                if not leveli == 0:\n",
    "                    new_col += sep\n",
    "                new_col += level\n",
    "        return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cat_encoding(list, dataframe, target):\n",
    "    for i in range(len(list)):\n",
    "        group_df = dataframe.groupby([list[i]], as_index=False).agg({target:{\"mean\"+list[i]:'mean', \n",
    "                                                                    \"stdev\"+list[i]:'std'}})\n",
    "        dataframe = pd.merge(dataframe, group_df, on=list[i], how='left')\n",
    "    \n",
    "    dataframe.columns = dataframe.columns.map(flattenHierarchicalCol)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = cat_encoding(catvarlist,df_cat_encod,target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some stdev values should be zero as a particular level may appear only once. Those values show up as NaN in our data\n",
    "# and have to be replaced\n",
    "\n",
    "new.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# there are no missing values or NaN now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>...</th>\n",
       "      <th>logloss,meancat112</th>\n",
       "      <th>logloss,stdevcat112</th>\n",
       "      <th>logloss,meancat113</th>\n",
       "      <th>logloss,stdevcat113</th>\n",
       "      <th>logloss,stdevcat114</th>\n",
       "      <th>logloss,meancat114</th>\n",
       "      <th>logloss,meancat115</th>\n",
       "      <th>logloss,stdevcat115</th>\n",
       "      <th>logloss,meancat116</th>\n",
       "      <th>logloss,stdevcat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>B</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>BU</td>\n",
       "      <td>...</td>\n",
       "      <td>7.824107</td>\n",
       "      <td>0.788870</td>\n",
       "      <td>7.623499</td>\n",
       "      <td>0.758090</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>7.667584</td>\n",
       "      <td>0.797272</td>\n",
       "      <td>7.675181</td>\n",
       "      <td>0.779026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T</td>\n",
       "      <td>L</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>...</td>\n",
       "      <td>7.416764</td>\n",
       "      <td>0.844268</td>\n",
       "      <td>7.634536</td>\n",
       "      <td>0.815351</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>7.667584</td>\n",
       "      <td>0.797272</td>\n",
       "      <td>7.688910</td>\n",
       "      <td>0.846272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>L</td>\n",
       "      <td>O</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>AB</td>\n",
       "      <td>...</td>\n",
       "      <td>7.747183</td>\n",
       "      <td>0.812036</td>\n",
       "      <td>7.676491</td>\n",
       "      <td>0.802501</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>7.652835</td>\n",
       "      <td>0.814291</td>\n",
       "      <td>7.628363</td>\n",
       "      <td>0.744062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>...</td>\n",
       "      <td>7.702934</td>\n",
       "      <td>0.785849</td>\n",
       "      <td>7.649874</td>\n",
       "      <td>0.810725</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>7.667584</td>\n",
       "      <td>0.797272</td>\n",
       "      <td>7.649112</td>\n",
       "      <td>0.814152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>K</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>7.654967</td>\n",
       "      <td>0.773446</td>\n",
       "      <td>7.634536</td>\n",
       "      <td>0.815351</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>7.677612</td>\n",
       "      <td>0.821570</td>\n",
       "      <td>7.711219</td>\n",
       "      <td>0.805475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat99 cat100 cat101 cat103 cat104 cat105 cat106 cat107 cat108 cat109  \\\n",
       "0     T      B      G      A      I      E      G      J      G     BU   \n",
       "1     T      L      F      A      E      E      I      K      K     BI   \n",
       "2     D      L      O      B      E      F      H      F      A     AB   \n",
       "3     T      I      D      A      E      E      I      K      K     BI   \n",
       "4     P      F      J      A      D      E      K      G      B      H   \n",
       "\n",
       "          ...          logloss,meancat112 logloss,stdevcat112  \\\n",
       "0         ...                    7.824107            0.788870   \n",
       "1         ...                    7.416764            0.844268   \n",
       "2         ...                    7.747183            0.812036   \n",
       "3         ...                    7.702934            0.785849   \n",
       "4         ...                    7.654967            0.773446   \n",
       "\n",
       "  logloss,meancat113 logloss,stdevcat113 logloss,stdevcat114  \\\n",
       "0           7.623499            0.758090            0.793651   \n",
       "1           7.634536            0.815351            0.793651   \n",
       "2           7.676491            0.802501            0.793651   \n",
       "3           7.649874            0.810725            0.793651   \n",
       "4           7.634536            0.815351            0.793651   \n",
       "\n",
       "  logloss,meancat114 logloss,meancat115  logloss,stdevcat115  \\\n",
       "0           7.774948           7.667584             0.797272   \n",
       "1           7.774948           7.667584             0.797272   \n",
       "2           7.774948           7.652835             0.814291   \n",
       "3           7.774948           7.667584             0.797272   \n",
       "4           7.774948           7.677612             0.821570   \n",
       "\n",
       "   logloss,meancat116  logloss,stdevcat116  \n",
       "0            7.675181             0.779026  \n",
       "1            7.688910             0.846272  \n",
       "2            7.628363             0.744062  \n",
       "3            7.649112             0.814152  \n",
       "4            7.711219             0.805475  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del new['logloss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat99', 'cat100', 'cat101', 'cat103', 'cat104', 'cat105', 'cat106',\n",
       "       'cat107', 'cat108', 'cat109', 'cat110', 'cat111', 'cat112', 'cat113',\n",
       "       'cat114', 'cat115', 'cat116', 'logloss,stdevcat99', 'logloss,meancat99',\n",
       "       'logloss,stdevcat100', 'logloss,meancat100', 'logloss,stdevcat101',\n",
       "       'logloss,meancat101', 'logloss,stdevcat103', 'logloss,meancat103',\n",
       "       'logloss,meancat104', 'logloss,stdevcat104', 'logloss,stdevcat105',\n",
       "       'logloss,meancat105', 'logloss,stdevcat106', 'logloss,meancat106',\n",
       "       'logloss,stdevcat107', 'logloss,meancat107', 'logloss,meancat108',\n",
       "       'logloss,stdevcat108', 'logloss,meancat109', 'logloss,stdevcat109',\n",
       "       'logloss,meancat110', 'logloss,stdevcat110', 'logloss,meancat111',\n",
       "       'logloss,stdevcat111', 'logloss,stdevcat112', 'logloss,meancat112',\n",
       "       'logloss,stdevcat113', 'logloss,meancat113', 'logloss,meancat114',\n",
       "       'logloss,stdevcat114', 'logloss,meancat115', 'logloss,stdevcat115',\n",
       "       'logloss,stdevcat116', 'logloss,meancat116'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = new.columns\n",
    "names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # Removing the word 'loss' from the left of the newly created columns\n",
    "new.rename(columns = lambda x: x.replace('logloss,',''), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat99</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>H</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>BC</td>\n",
       "      <td>A</td>\n",
       "      <td>J</td>\n",
       "      <td>AX</td>\n",
       "      <td>A</td>\n",
       "      <td>Q</td>\n",
       "      <td>HG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>F</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>CO</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>X</td>\n",
       "      <td>A</td>\n",
       "      <td>L</td>\n",
       "      <td>HK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>BI</td>\n",
       "      <td>CS</td>\n",
       "      <td>C</td>\n",
       "      <td>U</td>\n",
       "      <td>AE</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>CK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "      <td>BI</td>\n",
       "      <td>CR</td>\n",
       "      <td>A</td>\n",
       "      <td>AY</td>\n",
       "      <td>AJ</td>\n",
       "      <td>A</td>\n",
       "      <td>P</td>\n",
       "      <td>DJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>E</td>\n",
       "      <td>G</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>AB</td>\n",
       "      <td>EG</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>C</td>\n",
       "      <td>J</td>\n",
       "      <td>HA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat99 cat100 cat101 cat103 cat104 cat105 cat106 cat107 cat108 cat109 cat110  \\\n",
       "0     T      H      G      A      G      E      I      L      K     BI     BC   \n",
       "1     P      B      D      A      G      G      G      F      B     BI     CO   \n",
       "2     D      G      Q      D      D      E      J      G      A     BI     CS   \n",
       "3     T      G      A      D      E      E      I      K      K     BI     CR   \n",
       "4     P      A      A      A      F      E      G      E      B     AB     EG   \n",
       "\n",
       "  cat111 cat112 cat113 cat114 cat115 cat116  \n",
       "0      A      J     AX      A      Q     HG  \n",
       "1      E      G      X      A      L     HK  \n",
       "2      C      U     AE      A      K     CK  \n",
       "3      A     AY     AJ      A      P     DJ  \n",
       "4      A      E      I      C      J     HA  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encod_test = df_test[catvarlist]\n",
    "cat_encod_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new2 = new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new2 = new2.drop(new2[catvarlist],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new2_onlystdev = new2.filter(like='stdev', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdev_names  = new2_onlystdev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new2_onlymean = new2.filter(like='mean', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meancat99', 'meancat100', 'meancat101', 'meancat103', 'meancat104',\n",
       "       'meancat105', 'meancat106', 'meancat107', 'meancat108', 'meancat109',\n",
       "       'meancat110', 'meancat111', 'meancat112', 'meancat113', 'meancat114',\n",
       "       'meancat115', 'meancat116'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_names = new2_onlymean.columns\n",
    "mean_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Index.sort of Index(['meancat99', 'meancat100', 'meancat101', 'meancat103', 'meancat104',\n",
       "       'meancat105', 'meancat106', 'meancat107', 'meancat108', 'meancat109',\n",
       "       'meancat110', 'meancat111', 'meancat112', 'meancat113', 'meancat114',\n",
       "       'meancat115', 'meancat116'],\n",
       "      dtype='object')>"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdev_names.sort\n",
    "mean_names.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting a dictionary based on training set encoding\n",
    "for i in range(len(catvarlist)):\n",
    "    mydict = dict(zip(new[catvarlist[i]], new[mean_names[i]]))\n",
    "    cat_encod_test[mean_names[i]] = cat_encod_test[catvarlist[i]].map(mydict)\n",
    "    mydict2 = dict(zip(new[catvarlist[i]], new[stdev_names[i]]))\n",
    "    cat_encod_test[stdev_names[i]] = cat_encod_test[catvarlist[i]].map(mydict2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cat_encod_test2 = cat_encod_test\n",
    "cat_encod_test2 = cat_encod_test2.drop(cat_encod_test2[catvarlist],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cat116</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>HG</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.246911</td>\n",
       "      <td>0.402922</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>HK</td>\n",
       "      <td>0.620805</td>\n",
       "      <td>0.654310</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>CK</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.711159</td>\n",
       "      <td>0.412789</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>DJ</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>HA</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.263570</td>\n",
       "      <td>0.696873</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9    ...    cat116     cont2  \\\n",
       "0   4    A    B    A    A    A    A    A    A    B    ...        HG  0.299102   \n",
       "1   6    A    B    A    B    A    A    A    A    B    ...        HK  0.620805   \n",
       "2   9    A    B    A    B    B    A    B    A    B    ...        CK  0.737068   \n",
       "3  12    A    A    A    A    B    A    A    A    A    ...        DJ  0.681761   \n",
       "4  15    B    A    A    A    A    B    A    A    A    ...        HA  0.299102   \n",
       "\n",
       "      cont3     cont4     cont5     cont7    cont8    cont12    cont13  \\\n",
       "0  0.246911  0.402922  0.281143  0.317681  0.61229  0.369858  0.704052   \n",
       "1  0.654310  0.946616  0.836443  0.443760  0.71330  0.675759  0.453468   \n",
       "2  0.711159  0.412789  0.718531  0.325779  0.29758  0.241676  0.258586   \n",
       "3  0.592681  0.354893  0.397069  0.342355  0.40028  0.341872  0.592264   \n",
       "4  0.263570  0.696873  0.302678  0.391833  0.23688  0.352251  0.301535   \n",
       "\n",
       "     cont14  \n",
       "0  0.392562  \n",
       "1  0.208045  \n",
       "2  0.297232  \n",
       "3  0.555955  \n",
       "4  0.825823  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending the above to the original test set and dropping the original variables from test set\n",
    "\n",
    "df_test_encoded = df_test\n",
    "df_test_encoded.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df_test_encoded['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test_encoded = df_test_encoded.drop(df_test_encoded[catvarlist], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>meancat112</th>\n",
       "      <th>stdevcat112</th>\n",
       "      <th>meancat113</th>\n",
       "      <th>stdevcat113</th>\n",
       "      <th>meancat114</th>\n",
       "      <th>stdevcat114</th>\n",
       "      <th>meancat115</th>\n",
       "      <th>stdevcat115</th>\n",
       "      <th>meancat116</th>\n",
       "      <th>stdevcat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>7.584808</td>\n",
       "      <td>0.834366</td>\n",
       "      <td>7.707454</td>\n",
       "      <td>0.818339</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.720294</td>\n",
       "      <td>0.793610</td>\n",
       "      <td>7.599985</td>\n",
       "      <td>0.783922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>7.794440</td>\n",
       "      <td>0.764510</td>\n",
       "      <td>7.675880</td>\n",
       "      <td>0.815698</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.717597</td>\n",
       "      <td>0.792957</td>\n",
       "      <td>7.690697</td>\n",
       "      <td>0.838854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>7.502006</td>\n",
       "      <td>0.842471</td>\n",
       "      <td>7.649874</td>\n",
       "      <td>0.810725</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.677612</td>\n",
       "      <td>0.821570</td>\n",
       "      <td>7.711219</td>\n",
       "      <td>0.805475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>7.655151</td>\n",
       "      <td>0.740239</td>\n",
       "      <td>7.663709</td>\n",
       "      <td>0.803780</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.689795</td>\n",
       "      <td>0.796498</td>\n",
       "      <td>7.649112</td>\n",
       "      <td>0.814152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>7.728269</td>\n",
       "      <td>0.819402</td>\n",
       "      <td>7.507995</td>\n",
       "      <td>0.763237</td>\n",
       "      <td>7.290746</td>\n",
       "      <td>0.784498</td>\n",
       "      <td>7.693859</td>\n",
       "      <td>0.832827</td>\n",
       "      <td>7.417526</td>\n",
       "      <td>0.617150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10     ...     meancat112  \\\n",
       "0    A    B    A    A    A    A    A    A    B     A     ...       7.584808   \n",
       "1    A    B    A    B    A    A    A    A    B     A     ...       7.794440   \n",
       "2    A    B    A    B    B    A    B    A    B     B     ...       7.502006   \n",
       "3    A    A    A    A    B    A    A    A    A     A     ...       7.655151   \n",
       "4    B    A    A    A    A    B    A    A    A     A     ...       7.728269   \n",
       "\n",
       "  stdevcat112 meancat113 stdevcat113 meancat114 stdevcat114 meancat115  \\\n",
       "0    0.834366   7.707454    0.818339   7.774948    0.793651   7.720294   \n",
       "1    0.764510   7.675880    0.815698   7.774948    0.793651   7.717597   \n",
       "2    0.842471   7.649874    0.810725   7.774948    0.793651   7.677612   \n",
       "3    0.740239   7.663709    0.803780   7.774948    0.793651   7.689795   \n",
       "4    0.819402   7.507995    0.763237   7.290746    0.784498   7.693859   \n",
       "\n",
       "  stdevcat115 meancat116 stdevcat116  \n",
       "0    0.793610   7.599985    0.783922  \n",
       "1    0.792957   7.690697    0.838854  \n",
       "2    0.821570   7.711219    0.805475  \n",
       "3    0.796498   7.649112    0.814152  \n",
       "4    0.832827   7.417526    0.617150  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encoded2 = pd.concat([df_test_encoded, cat_encod_test2], axis=1)\n",
    "df_test_encoded2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove duplicated columns\n",
    "remove = []\n",
    "cols = df_test_encoded2.columns\n",
    "for i in range(len(cols)-1):\n",
    "    v = df_test_encoded2[cols[i]].values\n",
    "    for j in range(i+1,len(cols)):\n",
    "        if np.array_equal(v,df_test_encoded2[cols[j]].values):\n",
    "            remove.append(cols[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_test_encoded2.head(5)\n",
    "df_test_encoded2.fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Doing the same with train set\n",
    "df_train_encoded = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train_encoded = df_train_encoded.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>2213.18</td>\n",
       "      <td>7.702637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>1283.60</td>\n",
       "      <td>7.158203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>3005.09</td>\n",
       "      <td>8.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>939.85</td>\n",
       "      <td>6.846784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>2763.85</td>\n",
       "      <td>7.924742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10    ...        cont3  \\\n",
       "0    A    B    A    B    A    A    A    A    B     A    ...     0.187583   \n",
       "1    A    B    A    A    A    A    A    A    B     B    ...     0.592681   \n",
       "2    A    B    A    A    B    A    A    A    B     B    ...     0.484196   \n",
       "3    B    B    A    B    A    A    A    A    B     A    ...     0.527991   \n",
       "4    A    B    A    B    A    A    A    A    B     B    ...     0.527991   \n",
       "\n",
       "      cont4     cont5     cont7    cont8    cont12    cont13    cont14  \\\n",
       "0  0.789639  0.310061  0.335060  0.30260  0.594646  0.822493  0.714843   \n",
       "1  0.614134  0.885834  0.436585  0.60087  0.366307  0.611431  0.304496   \n",
       "2  0.236924  0.397069  0.315545  0.27320  0.373424  0.195709  0.774425   \n",
       "3  0.373816  0.422268  0.391128  0.31796  0.321570  0.605077  0.602642   \n",
       "4  0.473202  0.704268  0.247408  0.24564  0.202213  0.246011  0.432606   \n",
       "\n",
       "      loss   logloss  \n",
       "0  2213.18  7.702637  \n",
       "1  1283.60  7.158203  \n",
       "2  3005.09  8.008396  \n",
       "3   939.85  6.846784  \n",
       "4  2763.85  7.924742  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_encoded.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train_encoded = df_train_encoded.drop(df_train_encoded[catvarlist], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#new = new.drop(new[catvarlist],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>stdevcat112</th>\n",
       "      <th>meancat112</th>\n",
       "      <th>stdevcat113</th>\n",
       "      <th>meancat113</th>\n",
       "      <th>meancat114</th>\n",
       "      <th>stdevcat114</th>\n",
       "      <th>meancat115</th>\n",
       "      <th>stdevcat115</th>\n",
       "      <th>stdevcat116</th>\n",
       "      <th>meancat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788870</td>\n",
       "      <td>7.824107</td>\n",
       "      <td>0.758090</td>\n",
       "      <td>7.623499</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.667584</td>\n",
       "      <td>0.797272</td>\n",
       "      <td>0.779026</td>\n",
       "      <td>7.675181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844268</td>\n",
       "      <td>7.416764</td>\n",
       "      <td>0.815351</td>\n",
       "      <td>7.634536</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.667584</td>\n",
       "      <td>0.797272</td>\n",
       "      <td>0.846272</td>\n",
       "      <td>7.688910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812036</td>\n",
       "      <td>7.747183</td>\n",
       "      <td>0.802501</td>\n",
       "      <td>7.676491</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.652835</td>\n",
       "      <td>0.814291</td>\n",
       "      <td>0.744062</td>\n",
       "      <td>7.628363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785849</td>\n",
       "      <td>7.702934</td>\n",
       "      <td>0.810725</td>\n",
       "      <td>7.649874</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.667584</td>\n",
       "      <td>0.797272</td>\n",
       "      <td>0.814152</td>\n",
       "      <td>7.649112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773446</td>\n",
       "      <td>7.654967</td>\n",
       "      <td>0.815351</td>\n",
       "      <td>7.634536</td>\n",
       "      <td>7.774948</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>7.677612</td>\n",
       "      <td>0.821570</td>\n",
       "      <td>0.805475</td>\n",
       "      <td>7.711219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10    ...     stdevcat112  \\\n",
       "0    A    B    A    B    A    A    A    A    B     A    ...        0.788870   \n",
       "1    A    B    A    A    A    A    A    A    B     B    ...        0.844268   \n",
       "2    A    B    A    A    B    A    A    A    B     B    ...        0.812036   \n",
       "3    B    B    A    B    A    A    A    A    B     A    ...        0.785849   \n",
       "4    A    B    A    B    A    A    A    A    B     B    ...        0.773446   \n",
       "\n",
       "  meancat112 stdevcat113 meancat113 meancat114 stdevcat114 meancat115  \\\n",
       "0   7.824107    0.758090   7.623499   7.774948    0.793651   7.667584   \n",
       "1   7.416764    0.815351   7.634536   7.774948    0.793651   7.667584   \n",
       "2   7.747183    0.802501   7.676491   7.774948    0.793651   7.652835   \n",
       "3   7.702934    0.810725   7.649874   7.774948    0.793651   7.667584   \n",
       "4   7.654967    0.815351   7.634536   7.774948    0.793651   7.677612   \n",
       "\n",
       "  stdevcat115 stdevcat116 meancat116  \n",
       "0    0.797272    0.779026   7.675181  \n",
       "1    0.797272    0.846272   7.688910  \n",
       "2    0.814291    0.744062   7.628363  \n",
       "3    0.797272    0.814152   7.649112  \n",
       "4    0.821570    0.805475   7.711219  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_train_encoded2 = pd.concat([df_train_encoded, new], axis=1)\n",
    "#df_train_encoded2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat = df_train_encoded.select_dtypes(include=[\"object\"])\n",
    "vars=[]\n",
    "vars = cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>logloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245921</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.594646</td>\n",
       "      <td>0.822493</td>\n",
       "      <td>0.714843</td>\n",
       "      <td>7.702637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.366307</td>\n",
       "      <td>0.611431</td>\n",
       "      <td>0.304496</td>\n",
       "      <td>7.158203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358319</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>0.774425</td>\n",
       "      <td>8.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555782</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.321570</td>\n",
       "      <td>0.605077</td>\n",
       "      <td>0.602642</td>\n",
       "      <td>6.846784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159990</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.202213</td>\n",
       "      <td>0.246011</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>7.924742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10    ...        cont2  \\\n",
       "0    A    B    A    B    A    A    A    A    B     A    ...     0.245921   \n",
       "1    A    B    A    A    A    A    A    A    B     B    ...     0.737068   \n",
       "2    A    B    A    A    B    A    A    A    B     B    ...     0.358319   \n",
       "3    B    B    A    B    A    A    A    A    B     A    ...     0.555782   \n",
       "4    A    B    A    B    A    A    A    A    B     B    ...     0.159990   \n",
       "\n",
       "      cont3     cont4     cont5     cont7    cont8    cont12    cont13  \\\n",
       "0  0.187583  0.789639  0.310061  0.335060  0.30260  0.594646  0.822493   \n",
       "1  0.592681  0.614134  0.885834  0.436585  0.60087  0.366307  0.611431   \n",
       "2  0.484196  0.236924  0.397069  0.315545  0.27320  0.373424  0.195709   \n",
       "3  0.527991  0.373816  0.422268  0.391128  0.31796  0.321570  0.605077   \n",
       "4  0.527991  0.473202  0.704268  0.247408  0.24564  0.202213  0.246011   \n",
       "\n",
       "     cont14   logloss  \n",
       "0  0.714843  7.702637  \n",
       "1  0.304496  7.158203  \n",
       "2  0.774425  8.008396  \n",
       "3  0.602642  6.846784  \n",
       "4  0.432606  7.924742  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_train_encoded['loss']\n",
    "del df_test['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we have both our train and test sets with categorical variables >10 levels encoded. Before modeling, we need to encode all\n",
    "# variables into numeric to use scikit learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for cf in vars:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_train_encoded[cf].unique())\n",
    "    df_train_encoded[cf] = le.transform(df_train_encoded[cf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Doing the same for test too\n",
    "\n",
    "for cf in vars:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_test[cf].unique())\n",
    "    df_test[cf] = le.transform(df_test[cf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat116</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>169</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.246911</td>\n",
       "      <td>0.402922</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.369858</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.392562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>0.620805</td>\n",
       "      <td>0.654310</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.675759</td>\n",
       "      <td>0.453468</td>\n",
       "      <td>0.208045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.711159</td>\n",
       "      <td>0.412789</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.241676</td>\n",
       "      <td>0.258586</td>\n",
       "      <td>0.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.341872</td>\n",
       "      <td>0.592264</td>\n",
       "      <td>0.555955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>163</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.263570</td>\n",
       "      <td>0.696873</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.825823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10    ...     \\\n",
       "0     0     1     0     0     0     0     0     0     1      0    ...      \n",
       "1     0     1     0     1     0     0     0     0     1      0    ...      \n",
       "2     0     1     0     1     1     0     1     0     1      1    ...      \n",
       "3     0     0     0     0     1     0     0     0     0      0    ...      \n",
       "4     1     0     0     0     0     1     0     0     0      0    ...      \n",
       "\n",
       "   cat116     cont2     cont3     cont4     cont5     cont7    cont8  \\\n",
       "0     169  0.299102  0.246911  0.402922  0.281143  0.317681  0.61229   \n",
       "1     173  0.620805  0.654310  0.946616  0.836443  0.443760  0.71330   \n",
       "2      51  0.737068  0.711159  0.412789  0.718531  0.325779  0.29758   \n",
       "3      76  0.681761  0.592681  0.354893  0.397069  0.342355  0.40028   \n",
       "4     163  0.299102  0.263570  0.696873  0.302678  0.391833  0.23688   \n",
       "\n",
       "     cont12    cont13    cont14  \n",
       "0  0.369858  0.704052  0.392562  \n",
       "1  0.675759  0.453468  0.208045  \n",
       "2  0.241676  0.258586  0.297232  \n",
       "3  0.341872  0.592264  0.555955  \n",
       "4  0.352251  0.301535  0.825823  \n",
       "\n",
       "[5 rows x 125 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Taking indep and dep variable into separate lists\n",
    "\n",
    "#df_train_encoded2['loss'] = df_train['loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#del df_train_encoded2['logloss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indep_vars = list(df_train_encoded)\n",
    "indep_vars.remove('logloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Variable selection using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold, KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "\n",
    "def timer(start_time=None):\n",
    "    if not start_time:\n",
    "        start_time = datetime.now()\n",
    "        return start_time\n",
    "    elif start_time:\n",
    "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n",
    "        print(' Time taken: %i minutes and %s seconds.' % (tmin, round(tsec, 2)))\n",
    "\n",
    "\n",
    "y = np.array(df_train_encoded['logloss'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainc = df_train_encoded.drop(['logloss'], axis=1)\n",
    "testc = df_test\n",
    "ntrain = trainc.shape[0]\n",
    "ntest = testc.shape[0]\n",
    "train_test = pd.concat((trainc, testc)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(trainc)\n",
    "Xt = np.array(testc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 5 features.\n",
      " Time taken: 12 minutes and 29.93 seconds.\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=20, max_depth=5, n_jobs=1)\n",
    "rfecv = RFECV(estimator=rfr,\n",
    "              step=20,\n",
    "              cv=KFold(y.shape[0],\n",
    "                       n_folds=5,\n",
    "                       shuffle=False,\n",
    "                       random_state=101),\n",
    "              scoring='mean_absolute_error',\n",
    "              verbose=2)\n",
    "\n",
    "\n",
    "# Estimate feature importance and time the whole process\n",
    "start_time = timer(None)\n",
    "rfecv.fit(X, y)\n",
    "timer(start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Optimal number of features: 25\n",
      " The selected features are ['cat1', 'cat2', 'cat6', 'cat7', 'cat11', 'cat12', 'cat24', 'cat44', 'cat53', 'cat57', 'cat72', 'cat77', 'cat79', 'cat80', 'cat81', 'cat94', 'cat100', 'cat101', 'cat103', 'cat111', 'cat114', 'cont2', 'cont7', 'cont12', 'cont14']\n"
     ]
    }
   ],
   "source": [
    "all_features = [x for x in trainc.columns]\n",
    "\n",
    "# Summarize the output\n",
    "print(' Optimal number of features: %d' % rfecv.n_features_)\n",
    "sel_features = [f for f, s in zip(all_features, rfecv.support_) if s]\n",
    "print(' The selected features are {}'.format(sel_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# But random forest regressor with RFE should be run at least with n_estimators=200 and step =4 or lesser. Due to computing \n",
    "# constraints it hasn't been done here. Based on other users who ran RFE with those parameters the following variables were\n",
    "#selected\n",
    "sel_features2 = []\n",
    "sel_features2 =  ['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9', 'cat10', \n",
    "                  'cat11', 'cat12', 'cat13', 'cat14', 'cat16', 'cat17', 'cat23', 'cat24', 'cat25', \n",
    "                  'cat26', 'cat27', 'cat28', 'cat29', 'cat31', 'cat32', 'cat36', 'cat37', 'cat38', \n",
    "                  'cat39', 'cat40', 'cat41', 'cat42', 'cat43', 'cat44', 'cat45', 'cat46', 'cat47', \n",
    "                  'cat49', 'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat57', 'cat58', 'cat59', \n",
    "                  'cat61', 'cat65', 'cat66', 'cat67', 'cat71', 'cat72', 'cat73', 'cat74', 'cat75', \n",
    "                  'cat76', 'cat78', 'cat79', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84', 'cat85', \n",
    "                  'cat86', 'cat87', 'cat89', 'cat90', 'cat91', 'cat92', 'cat93', 'cat94', 'cat95', \n",
    "                  'cat96', 'cat97', 'cat98', 'cat99', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104', \n",
    "                  'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat110', 'cat111', 'cat112', \n",
    "                  'cat113', 'cat114', 'cat115', 'cat116','cont2', 'cont3', 'cont4', 'cont5', \n",
    "                  'cont7', 'cont8', 'cont12', 'cont13', 'cont14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Building a basic linear model and testing based on these variables\n",
    "# Building our first model using these variables\n",
    "# Defining a function to fit model and perform cross validation\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_model(model, data, predictors, outcome):\n",
    "  \n",
    "    #Fit the model:\n",
    "    model.fit(data[predictors],data[outcome])\n",
    "       \n",
    "    \n",
    "    #Perform k-fold cross-validation with 5 folds\n",
    "    kf = KFold(data.shape[0], n_folds=5)\n",
    "    error = []\n",
    "    for train, test in kf:\n",
    "        # Filter training data\n",
    "        train_predictors = (data[predictors].iloc[train,:])\n",
    "    \n",
    "        # The target we're using to train the algorithm.\n",
    "        train_target = data[outcome].iloc[train]\n",
    "    \n",
    "        # Training the algorithm using the predictors and target.\n",
    "        model.fit(train_predictors, train_target)\n",
    "        \n",
    "        #Record error from each cross-validation run\n",
    "        error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n",
    " \n",
    "        print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = ['logloss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Score : 48.569%\n",
      "Cross-Validation Score : 48.624%\n",
      "Cross-Validation Score : 48.524%\n",
      "Cross-Validation Score : 48.464%\n",
      "Cross-Validation Score : 48.462%\n"
     ]
    }
   ],
   "source": [
    "# Running model\n",
    "model = LinearRegression()\n",
    "\n",
    "fit_model(model, df_train_encoded, sel_features2, target[0])\n",
    "\n",
    "# errors are still high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test2 = df_test[sel_features2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Our mean errors are very high!\n",
    "\n",
    "# Predictions\n",
    "df_test2['predictions'] = np.exp(model.predict(df_test2))\n",
    "\n",
    "#del df_test2['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Writing to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\HP\\\\Desktop\\\\Kaggle\\\\All State Severity Claims'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os  \n",
    "os.chdir('C:\\\\Users\\\\HP\\\\Desktop\\\\Kaggle\\\\All State Severity Claims')\n",
    "os.getcwd()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Writing predictions to csv for submission\n",
    "df_test2.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# But RFE is not a very stable method for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_train_encoded2[indep_vars]\n",
    "Y  = df_train_encoded2[target]\n",
    "names = df_train_encoded2[indep_vars].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\randomized_l1.py:53: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  for _ in range(n_resampling)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.85999999999999999, 'cat80'), (0.80000000000000004, 'cat79'), (0.59999999999999998, 'cat57'), (0.57999999999999996, 'cat81'), (0.56000000000000005, 'meancat100'), (0.54000000000000004, 'meancat101'), (0.52000000000000002, 'cat87'), (0.47999999999999998, 'meancat116'), (0.44, 'meancat103'), (0.41999999999999998, 'stdevcat113'), (0.40000000000000002, 'cont2'), (0.40000000000000002, 'cat12'), (0.38, 'stdevcat100'), (0.32000000000000001, 'stdevcat116'), (0.32000000000000001, 'meancat113'), (0.32000000000000001, 'cat72'), (0.26000000000000001, 'cat1'), (0.23999999999999999, 'meancat111'), (0.22, 'stdevcat101'), (0.20000000000000001, 'cat7'), (0.17999999999999999, 'cat89'), (0.14000000000000001, 'meancat105'), (0.14000000000000001, 'cat11'), (0.14000000000000001, 'cat10'), (0.10000000000000001, 'stdevcat103'), (0.10000000000000001, 'meancat114'), (0.080000000000000002, 'cat2'), (0.080000000000000002, 'cat13'), (0.059999999999999998, 'cont7'), (0.040000000000000001, 'stdevcat111'), (0.02, 'stdevcat114'), (0.02, 'stdevcat105'), (0.02, 'meancat112'), (0.02, 'cont11'), (0.0, 'stdevcat99'), (0.0, 'stdevcat115'), (0.0, 'stdevcat112'), (0.0, 'stdevcat110'), (0.0, 'stdevcat109'), (0.0, 'stdevcat108'), (0.0, 'stdevcat107'), (0.0, 'stdevcat106'), (0.0, 'stdevcat104'), (0.0, 'meancat99'), (0.0, 'meancat115'), (0.0, 'meancat110'), (0.0, 'meancat109'), (0.0, 'meancat108'), (0.0, 'meancat107'), (0.0, 'meancat106'), (0.0, 'meancat104'), (0.0, 'cont9'), (0.0, 'cont8'), (0.0, 'cont6'), (0.0, 'cont5'), (0.0, 'cont4'), (0.0, 'cont3'), (0.0, 'cont14'), (0.0, 'cont13'), (0.0, 'cont12'), (0.0, 'cont10'), (0.0, 'cont1'), (0.0, 'cat98'), (0.0, 'cat97'), (0.0, 'cat96'), (0.0, 'cat95'), (0.0, 'cat94'), (0.0, 'cat93'), (0.0, 'cat92'), (0.0, 'cat91'), (0.0, 'cat90'), (0.0, 'cat9'), (0.0, 'cat88'), (0.0, 'cat86'), (0.0, 'cat85'), (0.0, 'cat84'), (0.0, 'cat83'), (0.0, 'cat82'), (0.0, 'cat8'), (0.0, 'cat78'), (0.0, 'cat77'), (0.0, 'cat76'), (0.0, 'cat75'), (0.0, 'cat74'), (0.0, 'cat73'), (0.0, 'cat71'), (0.0, 'cat70'), (0.0, 'cat69'), (0.0, 'cat68'), (0.0, 'cat67'), (0.0, 'cat66'), (0.0, 'cat65'), (0.0, 'cat64'), (0.0, 'cat63'), (0.0, 'cat62'), (0.0, 'cat61'), (0.0, 'cat60'), (0.0, 'cat6'), (0.0, 'cat59'), (0.0, 'cat58'), (0.0, 'cat56'), (0.0, 'cat55'), (0.0, 'cat54'), (0.0, 'cat53'), (0.0, 'cat52'), (0.0, 'cat51'), (0.0, 'cat50'), (0.0, 'cat5'), (0.0, 'cat49'), (0.0, 'cat48'), (0.0, 'cat47'), (0.0, 'cat46'), (0.0, 'cat45'), (0.0, 'cat44'), (0.0, 'cat43'), (0.0, 'cat42'), (0.0, 'cat41'), (0.0, 'cat40'), (0.0, 'cat4'), (0.0, 'cat39'), (0.0, 'cat38'), (0.0, 'cat37'), (0.0, 'cat36'), (0.0, 'cat35'), (0.0, 'cat34'), (0.0, 'cat33'), (0.0, 'cat32'), (0.0, 'cat31'), (0.0, 'cat30'), (0.0, 'cat3'), (0.0, 'cat29'), (0.0, 'cat28'), (0.0, 'cat27'), (0.0, 'cat26'), (0.0, 'cat25'), (0.0, 'cat24'), (0.0, 'cat23'), (0.0, 'cat22'), (0.0, 'cat21'), (0.0, 'cat20'), (0.0, 'cat19'), (0.0, 'cat18'), (0.0, 'cat17'), (0.0, 'cat16'), (0.0, 'cat15'), (0.0, 'cat14'), (0.0, 'cat102')]\n"
     ]
    }
   ],
   "source": [
    "# Using Randomized lasso for feature selection\n",
    "from sklearn.linear_model import RandomizedLasso\n",
    "rlasso = RandomizedLasso(alpha=0.025, n_resampling=50,max_iter =10,n_jobs =1)\n",
    "rlasso.fit(X, Y)\n",
    "\n",
    "print(\"Features sorted by their score:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), \n",
    "                 names), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_feats = {}\n",
    "final_feats = rank_to_dict(np.abs(rlasso.scores_), names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "\n",
    "final_feats = OrderedDict(sorted(final_feats.items(), key=itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_feats = {k:v for (k,v) in final_feats.items() if v > 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using all variables with co-eff > 0.10 (in this case only three will be left out) and running our first model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indep_vars_final=[]\n",
    "indep_vars_final = list(final_feats.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# We have 34 variables selected from our lasso feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Writing predictions to csv for submission\n",
    "X_test_lasso.to_csv(\"predictions_lasso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
